{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cabee050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import  numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D\n",
    "from keras_tuner import RandomSearch\n",
    "from keras_tuner.engine.hyperparameters import HyperParameters\n",
    "from sklearn.metrics import confusion_matrix , classification_report\n",
    "###Importing all the relevant libraries required for Image Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de21bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = datasets.mnist.load_data()  #Loading the Mnist data from keras library and splitting \n",
    "                                                                    # them between train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b97f39fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e56fd00b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eeb70f3be0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAI4AAACOCAYAAADn/TAIAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAIZklEQVR4nO3df2xVZxkH8O/T0kJhZFI2SC2FYSi/1Om0jv0w0UWquCjoNiKdMf2DBSFjOuOiY8Yff2CyxKFRMiNESacuMHUaFjdDxkSMZmNUUyezlnaGrhUCKwrUINCWxz/u3eU+R3p7+px7zz333u8nIT3POb09b8i373nvubfPFVUF0WRVFXsAVJoYHHJhcMiFwSEXBodcGBxyiRQcEVklIj0i0iciD+drUJR84r2PIyLVAI4CaAUwCOAwgDZV/Vv+hkdJNSXCY28G0Keq/wAAEdkDYA2AcYNTK1N1GmZEOCXFbRj/HlLV64P7owSnEcBAVj0IYEWuB0zDDKyQD0U4JcVtv/6i/2r7owRHrrLv/657IrIBwAYAmIbpEU5HSRJlcTwIoCmrngfgePCbVHWnqraoaksNpkY4HSVJlOAcBtAsIgtFpBbAOgDP5GdYlHTuS5WqjorIZgD7AFQD2KWqr+ZtZJRoUdY4UNXnADyXp7FQCeGdY3JhcMiFwSEXBodcGBxyYXDIhcEhFwaHXBgccmFwyIXBIRcGh1wYHHJhcMiFwSEXBodcGBxyYXDIhcEhFwaHXCK9Wb2SXPpIi6n7P305s73pPQfNsQdnHc35s975wwdMPf2E/TvGM7ddNPWCJ+3vd+2+ztyDjQFnHHJhcMiFwSEXrnHG8cbGW029/UuPm7pl6lhmuyrw+9d+bKWpb7r2dVP/5b7v5jx38OfdVt9m6vp9OR8eC8445MLgkAuDQy4Vu8aRmlpTX1j5LlM/veVbpn7rFNvbZ31/a2a7/7El5tiMZ7tMfWD6fFMf/NVie67m3N1hznXNNnV9zu+OB2cccpkwOCKyS0ROiciRrH31IvK8iPSmv84q7DApacLMOB0AVgX2PQzgBVVtBvBCuqYKMuEaR1V/LyI3BHavAfDB9PYTAH4H4Mv5HFihndhsX3t6+aHgvRW7plnb93FTj949ktmePnTIHAt20Dy+4b2mPtSc+z7Ob87PNPWiHQOmHs356Hh41zhzVfUEAKS/zsnfkKgUFPxZFdvVlifvjHNSRBoAIP311HjfyHa15ck74zwDoB3Ao+mve/M2ogLp3W6bvvfctd3Ul2Ete36jqZc+dMzUY0OnQ59746bJ/fds/Wa7qWcNvDipx8chzNPx3QBeBLBERAZFZD1SgWkVkV6kPgTk0cIOk5ImzLOqtnEO8UMZKhjvHJNL2b5W9dq2W0zdc5d9P83ZyxdMvfbv95p6yQP2fcNjw8Pjnqtqhv0opdP33GjqNdfY172qUGfqpT+/39SLOpK3pgnijEMuDA65MDjkUjZrnOq59lWPJz75fVNfDtypCa5palvtB8EF7+sEVb17eWb7Hbu6zbGtc78X+G574/P2rnWmXvIN+/gxJB9nHHJhcMilbC5VMs1eDrL/fOVq6j5n3zoqC5pM3btxnqk/vPLPpv7CnJ2Z7flT7NPr4GVuLPAR3fLUdfb4md6cY00izjjkwuCQC4NDLmWzxtELtjXIoYs1pl4xdcTUe/fvMXXw6fpE9v/3yjqld8SuYe6o+4+pOy/Z9dRbfpz8lxQmwhmHXBgccmFwyKVs1jhjJ+3bnr++6T5TP/YD+xLEjXbZgZ+es/dxth5cberFHfZtGFNOns1sz9n9L3Psjqbfmrr9gB3LYhS/FVtUnHHIhcEhFwaHXMpmjRMUbOn6yMKbJ/X4xXg55/HhNVd+3rPz7Z+/jKj9faw7FlhQlQHOOOTC4JALg0MuZbvGKbTRuiu/cyNq3/sTfN1rYYdtV5uENiVRccYhFwaHXBgccuEax2nmnpeuFNuKN45i4YxDLmH64zSJyAER6RaRV0Xk8+n9bFlbwcLMOKMAvqiqywDcAuB+EVkOtqytaGEaK50A8GaH0WER6QbQiDJoWRvF8LrsNip/Kto4imVSa5x0v+ObABwCW9ZWtNDBEZFrADwN4EFVPTeJx20QkU4R6RzBxYkfQCUhVHBEpAap0Dypqr9M7w7VspbtastTmGdVAuBHALpV9dtZh95sWQuUSMvafDr7tqrMv0oU5gbg7QA+A+CvItKV3vcIUi1qf5ZuX/s6gLUFGSElUphnVX8AIOMcZsvaClWZ8yxFxteqnBoPns9s12yuNsdGgp87VIY445ALg0MuDA65cI3jJH/symx3nLOvtrTN/Kepz7+9wdS1A4MFG1dcOOOQC4NDLrxU5cF3dtxj6rbAJwo3fLXP1KfP2E+XwUuvFGRchcQZh1wYHHJhcMiFa5w8aPxJj6k/9YmPmfqpRb829Qe+Zj/mtP7ea009duYsko4zDrkwOOTC4JAL1zh5MDZ02tSX7p5t6mXbPmvq7pU7TL166Xr7A0vgvg5nHHJhcMiFwSEXrnEKILjmaW639Wq8L/CI5K9pgjjjkAuDQy4MDrmIanx/yyEibwDoB3AdgKHYTjw5HJu1QFWvD+6MNTiZk4p0qmpL7CcOgWMLh5cqcmFwyKVYwdlZpPOGwbGFUJQ1DpU+XqrIJdbgiMgqEekRkT4RKWp7WxHZJSKnRORI1r5E9G4uhd7SsQVHRKoBPA7gowCWA2hL90sulg4AqwL7ktK7Ofm9pVU1ln8AbgWwL6veAmBLXOcfZ0w3ADiSVfcAaEhvNwDoKeb4ssa1F0BrksYX56WqEcBAVj2Y3pckievdnNTe0nEG52p9BPmULgdvb+k4xBmcQQBNWfU8AMdjPH8YoXo3xyFKb+k4xBmcwwCaRWShiNQCWIdUr+QkSUTv5pLoLR3zIu9OAEcBvAbgK0VecO5G6sNNRpCaDdcDmI3Us5Xe9Nf6Io3t/Uhdxl8B0JX+d2dSxqeqvHNMPrxzTC4MDrkwOOTC4JALg0MuDA65MDjkwuCQy/8ASzYBF0fD/m4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x144 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,2))\n",
    "plt.imshow(x_train[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdec9a5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, ..., 4, 5, 6], dtype=uint8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9048a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 5, 6, 8], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9809678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255           ###Resizing the images ranging between 0 and 1\n",
    "x_test = x_test/255             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d3ce61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a910815d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(len(x_train),28,28,1)  ###Reshaping the images\n",
    "x_test = x_test.reshape(len(x_test),28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c0c2175e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94f2ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "###Keras Tuner model to select the best number of parameters by choosing the appropriate values\n",
    "def build_model(hp):  \n",
    "  model = Sequential([\n",
    "        Conv2D(\n",
    "        filters=hp.Int('conv_1_filter', min_value=32, max_value=128, step=16),\n",
    "        kernel_size=hp.Choice('conv_1_kernel', values = [3,5]),\n",
    "        activation='relu',\n",
    "        input_shape=(28,28,1)\n",
    "    ),\n",
    "        Conv2D(\n",
    "        filters=hp.Int('conv_2_filter', min_value=32, max_value=64, step=16),\n",
    "        kernel_size=hp.Choice('conv_2_kernel', values = [3,5]),\n",
    "        activation='relu'\n",
    "    ),\n",
    "        Flatten(),\n",
    "        Dense(\n",
    "        units=hp.Int('dense_1_units', min_value=32, max_value=128, step=16),\n",
    "        activation='relu'\n",
    "    ),\n",
    "        Dense(10, activation='softmax')\n",
    "  ])\n",
    "  \n",
    "  model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', values=[1e-2, 1e-3])),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "  \n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81400ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuner_search=RandomSearch(build_model,   ###Fitting the model into tuner with the number of trials\n",
    "                          objective='val_accuracy',\n",
    "                          max_trials=2,directory='output',project_name=\"Mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05473174",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 Complete [00h 10m 22s]\n",
      "val_accuracy: 0.9624444246292114\n",
      "\n",
      "Best val_accuracy So Far: 0.9755555391311646\n",
      "Total elapsed time: 00h 31m 05s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "tuner_search.search(x_train,y_train,epochs=3,validation_split=0.15)    ###Finally performing training and seleting the best \n",
    "                                                                       ###model for best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c1f9f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = tuner_search.get_best_models(num_models=1)          ###Saving the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "621f917e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16ce31a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 24, 24, 96)        2496      \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 20, 20, 48)        115248    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 19200)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 48)                921648    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 10)                490       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,039,882\n",
      "Trainable params: 1,039,882\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f7fc7297",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/7\n",
      "1594/1594 [==============================] - 382s 240ms/step - loss: 0.0863 - accuracy: 0.9764 - val_loss: 0.0870 - val_accuracy: 0.9778\n",
      "Epoch 5/7\n",
      "1594/1594 [==============================] - 378s 237ms/step - loss: 0.0766 - accuracy: 0.9807 - val_loss: 0.1096 - val_accuracy: 0.9731\n",
      "Epoch 6/7\n",
      "1594/1594 [==============================] - 376s 236ms/step - loss: 0.0693 - accuracy: 0.9828 - val_loss: 0.1186 - val_accuracy: 0.9780\n",
      "Epoch 7/7\n",
      "1594/1594 [==============================] - 302s 189ms/step - loss: 0.0674 - accuracy: 0.9840 - val_loss: 0.1807 - val_accuracy: 0.9730\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1eeb70f0970>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=7, validation_split=0.15, initial_epoch=3)  ###Finally Training the best model and \n",
    "                                                                               ###obtaining the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bbefc523",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)   ###Predicting the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "92d31e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.97      0.98       980\n",
      "           1       0.98      0.99      0.98      1135\n",
      "           2       0.97      0.97      0.97      1032\n",
      "           3       0.96      0.98      0.97      1010\n",
      "           4       0.94      0.99      0.97       982\n",
      "           5       0.95      0.97      0.96       892\n",
      "           6       0.97      0.98      0.97       958\n",
      "           7       0.98      0.96      0.97      1028\n",
      "           8       0.98      0.95      0.96       974\n",
      "           9       0.98      0.94      0.96      1009\n",
      "\n",
      "    accuracy                           0.97     10000\n",
      "   macro avg       0.97      0.97      0.97     10000\n",
      "weighted avg       0.97      0.97      0.97     10000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred_classes = [np.argmax(element) for element in y_pred]  ###Getting the report\n",
    "\n",
    "print(\"Classification Report: \\n\", classification_report(y_test, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bfa6d5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 2, 1, 0, 4]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_classes = [np.argmax(element) for element in y_pred]\n",
    "y_classes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "06df5082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4], dtype=uint8)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e1d6bf0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1eeb9156970>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0cd1c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
